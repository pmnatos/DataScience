{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network\n",
    "\n",
    "Let's create a simple neural network. Fill the gaps with the correct variables/values. Our Neural Network has one hidden layer and two inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights:  [[0.30191979 0.78144931]\n",
      " [0.2160805  0.48203332]]\n",
      "Difference in the outcome:  [[-0.68990603]\n",
      " [ 0.31009397]\n",
      " [ 0.16442336]\n",
      " [ 0.16442336]]\n",
      "Final weights:  [[ 1.65731924  1.63074525]\n",
      " [-0.65719213 -0.41585895]]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "#activation funcion\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "#class of your neural network\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    #set the features of your neural network\n",
    "    def __init__(self, x, y):\n",
    "        #set the training input\n",
    "        self.input      = x\n",
    "        #randomly assign the weights for the different layers\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],2) \n",
    "        self.weights2   = np.random.rand(2,1) \n",
    "        #set the output for the training input set\n",
    "        self.y          = y\n",
    "        #add zeros as initial output\n",
    "        self.output     = np.zeros(self.y.shape)\n",
    "    #feedforward function \n",
    "    def feedforward(self):\n",
    "         #do the calculation for the input value of neurons in the hidden layer\n",
    "        hidden_node1 = sigmoid(self.input[0]*self.weights1[0][0]+self.input[1]*self.weights1[0][1])\n",
    "        hidden_node2 = sigmoid(self.input[0]*self.weights1[1][0]+self.input[1]*self.weights1[1][1])\n",
    "        #calculate the value of the hidden layer and the output of your network\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "        return self.output\n",
    "       #backpropagate the error\n",
    "    def backprop(self):\n",
    "        # chain rule to find the derivatives of the error with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, ((self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  (np.dot((self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "        # update the weights with the derivative of the error function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "        \n",
    "#test what you have done \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    X = np.array([[0,1],\n",
    "                  [0,1],\n",
    "                  [1,1],\n",
    "                  [1,1]])\n",
    "    y =  np.array([[0],[1],[1],[1]])\n",
    "    nn = NeuralNetwork(X,y)\n",
    "    print('Initial weights: ', nn.weights1)\n",
    "\n",
    "    for i in range(100):\n",
    "        nn.feedforward()\n",
    "        nn.backprop()\n",
    "    print('Difference in the outcome: ', nn.y - nn.output)\n",
    "    print('Final weights: ', nn.weights1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Network\n",
    "\n",
    "Compare for this the provided *UsefulLibraries* jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR Function\n",
    "Create an MLP classifier for the OR-Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "#insert here the training data you need for input and output\n",
    "X_training=[[0,0],[1,0],[0,1],[1,1]]\n",
    "y_training=[0,1,1,1]\n",
    "#create the corresponding net with the MLP classifier\n",
    "mynet = MLPClassifier()\n",
    "mynet.fit(X_training,y_training)\n",
    "# What is the output of your classifier for [1,1]?\n",
    "mynet.predict([[1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bipolar OR\n",
    "\n",
    "Instead of {0, 1}, we can also change the value into bipolar {-1, +1}. Try again to create a perceptron using the MLP Classifier for the OR-function with the bipolar output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "#insert here the training data you need for input and output\n",
    "X_training=[[1, 1], \n",
    "            [1, -1],\n",
    "            [-1, 1],\n",
    "            [-1, -1]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            -1\n",
    "           ]\n",
    "#create the corresponding net with the MLP classifier\n",
    "mynet = MLPClassifier()\n",
    "mynet.fit(X_training,y_training)\n",
    "# What is the output of your classifier for [1,1]?\n",
    "mynet.predict([[1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XNOR \n",
    "\n",
    "Create a XNOR net with 100% accuracy for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: True\n",
      "True\n",
      "Accuracy: True\n",
      "True\n",
      "Accuracy: True\n",
      "True\n",
      "Accuracy: True\n",
      "True\n",
      "Accuracy: True\n",
      "True\n",
      "Accuracy: True\n",
      "True\n",
      "Accuracy: True\n",
      "True\n",
      "Accuracy: True\n",
      "True\n",
      "Accuracy: False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "# the needed input\n",
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            0,\n",
    "            0,\n",
    "            0\n",
    "           ]\n",
    "# set the method and test until you have accuracy 100%\n",
    "hidden = 0\n",
    "step = 0\n",
    "accuracy = 0\n",
    "while (accuracy != 1.0) and  (step < 100):\n",
    "    hidden += 1\n",
    "    step += 1\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(hidden)) \n",
    "    mlp.fit(X_training, y_training)                    # training\n",
    "    y_pred=mlp.predict(X_training)     # show the output\n",
    "    accuracy  = metric.accuracy_score(np.array(y_training).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "    print('Accuracy:',accuracy != 1.0)\n",
    "    print((accuracy != 1.0 or step < 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 1.0\n",
      "Number of hidden layers:  9\n",
      "[(2, 9), (9, 1)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy=',accuracy)                         # show the accuracy score\n",
    "print('Number of hidden layers: ', hidden)\n",
    "\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "print(len(mlp.coefs_))                                  # synapsis weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
