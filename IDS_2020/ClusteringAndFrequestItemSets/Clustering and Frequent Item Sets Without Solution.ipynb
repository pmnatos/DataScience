{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and Frequent Item Sets\n",
    "\n",
    "#### In this section, we will learn about how to use k-means, DBSCAN, Apriori and FP-Growth in python.\n",
    "\n",
    "\n",
    "Following libraries are used for this algorithms:\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- mlxtend\n",
    "- sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read and explore  Weather.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from Weather.csv\n",
    "\n",
    "We use Weather.csv file as a data set for applying k-means, DBSCAN and Apriori algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the target CSV file 'Weather.csv', store the file contents in variable 'weather' which is Pandas.DataFrame\n",
    "\n",
    "weather = pd.read_csv('Weather.csv')\n",
    "weather.size\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first five rows in 'weather'\n",
    "weather.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show last five rows in 'weather'\n",
    "weather.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the name of the attributes in 'weather'\n",
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw a diagram for finding distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a variable 'temerature' which is an array of values from column 'Temperature' in variable 'weather'.\n",
    "\n",
    "# Make a variable 'humidity' which is an array of values from column 'Humidity' in variable 'weather'.\n",
    "\n",
    "temperature =weather['Temperature'].values\n",
    "humidity= weather['Humidity'].values\n",
    "\n",
    "# Draw a scatter diagram for showing the distribution of data item in variable 'information' \n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 10)\n",
    "plt.scatter(temperature, humidity, c='green', s =10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Experiments on k-means and DBSCAN by using Weather.csv\n",
    "For applying k-means and DBSCAN we should use sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import k-means module and DBSCAN module from sklearn\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  K-means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable 'weather_data'. Each row's of that is corresponding to the row in variable 'Weather' \n",
    "\n",
    "weather_data = np.array(list(zip(temperature, humidity)))\n",
    "\n",
    "#Define 'cluster_num' for for number of clusters.\n",
    "\n",
    "cluster_num = 3\n",
    "kmeans = KMeans(cluster_num).fit(weather_data)\n",
    "clusters = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "fig, plots = plt.subplots()\n",
    "colors = ['r', 'g', 'b', 'y', 'm']\n",
    "for cluster_index in range(cluster_num) :\n",
    "    sub_set = np.array([weather_data[i] for i in range(len(weather_data)) if clusters[i] == cluster_index])\n",
    "    if len(sub_set) == 0 :\n",
    "        continue\n",
    "    plots.scatter(sub_set[:,0], sub_set[:,1], s = 10, c = colors[cluster_index])\n",
    "plots.scatter(centroids[:,0], centroids[:,1], marker = '*', s = 300, c = 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Change the 'cluster_num' variable from 2 to 5. Which value clusters the data better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable 'weather_data'. Each row's of that is corresponding to the row in variable 'Weather' \n",
    "weather_data = np.array(list(zip(temperature, humidity)))\n",
    "\n",
    "#Define 'eps' variable 4 and min_samples varibale 8.\n",
    "\n",
    "dbscan = DBSCAN(eps = 4, min_samples=8).fit(weather_data)\n",
    "clusters = dbscan.labels_\n",
    "cluster_indexs = np.unique(clusters).tolist()\n",
    "print(cluster_indexs)\n",
    "\n",
    "fig, plots = plt.subplots()\n",
    "colors = ['r', 'g', 'b', 'y', 'm']\n",
    "for cluster_index in cluster_indexs :\n",
    "    sub_set = np.array([weather_data[i] for i in range(len(weather_data)) if clusters[i] == cluster_index])\n",
    "    if len(sub_set) == 0 :\n",
    "        continue\n",
    "    plots.scatter(sub_set[:,0], sub_set[:,1], s = 10, c = colors[cluster_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Change the 'eps' variable from 4 to 7 and min_samples from 8 to 11. Which value clusters the data better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Compare the result to the result from k-means when 'cluster_num = 3'. which result is better and why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dendograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weather = pd.read_csv('Weather2.csv')\n",
    "weather.size\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=weather\n",
    "print(data.head())\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "data_scaled = normalize(data)\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n",
    "print(data_scaled.head())\n",
    "\n",
    "import scipy.cluster.hierarchy as shc\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Dendrograms\")\n",
    "dend = shc.dendrogram(shc.linkage(data_scaled, method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Dendrograms\")\n",
    "dend = shc.dendrogram(shc.linkage(data_scaled, method='ward'))\n",
    "plt.axhline(y=2, color='b', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "cluster.fit_predict(data_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(data_scaled['Temperature'], data_scaled['Humidity'], c=cluster.labels_)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Apriori algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Apriori module and TransactionEncoder module from mlxtend\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import association_rules as arule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file repair.csv and \n",
    "\n",
    "repair_data = []\n",
    "with open(\"Repair.csv\") as csvFile:\n",
    "    reader = csv.reader(csvFile)\n",
    "    for row in reader:\n",
    "        repair_data.append(row)\n",
    "        \n",
    "#Show 3 first rows of repair_data\n",
    "\n",
    "repair_data[0:3][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn to use TransactionEncoder module to convert an array to DataFrame for Apriori algorithm in mlxtend\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(repair_data).transform(repair_data)\n",
    "data = pd.DataFrame(te_ary, columns = te.columns_)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn to use Apriori algorithm from mlxtend\n",
    "\n",
    "frequent_itemsets = apriori(data, min_support = 0.4, use_colnames = True)\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Change the value of min_support. What is the effect of that on number of itemsets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
